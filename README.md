# Knowledge-enriched Text Generation paper reading

üòéAwesome list of papers about knowledge-enhanced Question generation with notes.

:white_check_mark: : already reading carefully

:fire:: high citation in recent years

:hammer_and_wrench:: available code

---

## :grey_question: Question Generation

---

### :mountain_snow: Ground Breaking Work

* :white_check_mark::fire: :hammer_and_wrench: **Learning to Ask: Neural Question Generation for Reading Comprehension**, in ACL 2017. [[pdf]](https://arxiv.org/abs/1705.00106) [[official code (torch)](https://github.com/xinyadu/nqg)]
  * Â∞ÜÁ´ØÂà∞Á´ØËÆ≠ÁªÉÁöÑÁ•ûÁªèÁΩëÁªúÂ∫îÁî®‰∫éÈóÆÈ¢òÁîüÊàê
  * ÈááÁî®seq2seq+attentionÊ®°ÂûãÊû∂ÊûÑ
  * ÊëÜËÑ±‰∫ÜËΩ¨Êç¢ËßÑÂàô‰∏éÊ®°ÁâàÁöÑÂ±ÄÈôêÔºåÂèñÂæó‰∫ÜÁõ∏ÊØî‰∫é‰º†ÁªüÊñπÊ≥ïÊõ¥Â•ΩÁöÑÊÄßËÉΩ

```mermaid
graph LR
‰ªªÂä°ÈöæÁÇπ --Êõ¥Âä†Êé•Ëøë‰∫é‰∫∫Á±ª--> Âêå‰πâËØçÊõøÊç¢+Áü•ËØÜÂºïÂÖ• --> Áõ∏ÂÖ≥Â∑•‰Ωú --> ËøáÂéª:rule-based 
Áõ∏ÂÖ≥Â∑•‰Ωú --> ÂÖ∂‰ªñÊï∞ÊçÆÊò†Â∞ÑËá™ÁÑ∂ËØ≠Ë®Ä

Seq2Seq --> en((encoder)) --bidirectional--> softËÆ°ÁÆóÊ≥®ÊÑèÂäõÂàÜÊï∞ --> lstm((LSTM))  --> only-sentence
lstm --> sentence+paragraph --> truncateÊà™Êñ≠,ÂΩìÁÑ∂Êõ¥Â•ΩÁöÑÊñπÊ≥ïÊòØÂàáÁâá

Seq2Seq --> de((decoder)) --word-level-prediction--> LSTM((LSTM)) --> ÈöêËóèÂ±ÇÂàùÂßãÂåñ --basic-model --> Âè•Â≠êencoderÁöÑÊúÄÂêéÈöêËóèÂ±Ç
LSTM --oours--> Âè•Â≠ê+ÊÆµËêΩÁöÑencoderËæìÂá∫


```



* :white_check_mark: :fire: **Neural question generation from text: A preliminary study**, in EMNLP 2017. [[pdf](https://arxiv.org/abs/1704.01792)] 
  * Âú®ÁºñÁ†ÅÊó∂È¢ùÂ§ñËÄÉËôë‰∫ÜÁ≠îÊ°à‰ΩçÁΩÆ‰∏éËØ≠Ê≥ï‰ø°ÊÅØÔºåÂèñÂæó‰∫ÜÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ

```mermaid
graph LR
en((encoder)) --bi-GRU--> fe((feature-Rich)) --> word-vecotr
fe --> lexcial-feature-embedding-vectors --> POS+NER
fe --> answer-position-embedding --> BIO-tagging

word-vecotr --> ÂèåÂêëÁöÑÈöêËóèÂ±Ç
POS+NER --> ÂèåÂêëÁöÑÈöêËóèÂ±Ç
BIO-tagging --> ÂèåÂêëÁöÑÈöêËóèÂ±Ç

de((decoder)) --Â∏¶Ê≥®ÊÑèÂäõÊú∫Âà∂,‰ΩøÁî®Âä†ÊÄßÊ≥®ÊÑèÂäõ--> maxout-hidden+ÂÖ∑‰ΩìÈúÄË¶ÅÁúãreferenceËÆ∫Êñá
de --> GRU

de --> Copy-Mechanism,‰∏ÄÊ†∑‰ΩøÁî®Âä†ÊÄßÊ≥®ÊÑèÂäõ --> ËÆ°ÁÆóÂá∫Ê¶ÇÁéá‰ªésourceÂè•Â≠ê‰∏≠Áõ¥Êé•copyÂçïËØç
```



### :sun_with_face: QG examples

* :white_check_mark: :hammer_and_wrench: **Mixture Content Selection for Diverse Sequence Generation**, in EMNLP 2019.[[pdf](https://arxiv.org/abs/1909.01953)] [[torch](https://github.com/clovaai/FocusSeq2Seq)]
* :hammer_and_wrench: **Radial Graph Convolutional Network for Visual Question Generation**, in IEEE Transactions on Neural Networks and Learning Systems 2020. [[pdf](https://ieeexplore.ieee.org/document/9079208)] [[torch](https://github.com/Wangt-CN/VQG-GCN)]

## :bookmark_tabs: Question Answering

---

*  :fire: :hammer_and_wrench:**[Question Answering] Commonsense for Generative Multi-Hop Question Answering Tasks**, in EMNLP 2018. [[pdf\]](https://arxiv.org/abs/1809.06309) [[code (tf)\]](https://github.com/yicheng-w/CommonSenseMultiHopQA)
* :hammer_and_wrench:**[Dialogue System] Improving Knowledge-aware Dialogue Generation via Knowledge Base Question Answering**, in AAAI 2020. [[pdf\]](https://arxiv.org/abs/1912.07491) [[code (torch)\]](https://github.com/siat-nlp/TransDG)
* **[Question Answering] Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs**, in EMNLP 2019. [[pdf\]](https://arxiv.org/abs/1910.08435)
* :fire::hammer_and_wrench:**[Question Answering] ** **Improving Multi-hop Question Answering over Knowledge Graphs usingKnowledge Base Embeddings**, in ACL 2020. [[pdf](https://aclanthology.org/2020.acl-main.412/)] [[torch](https://github.com/malllabiisc/EmbedKGQA)]



## :book: Other Related Topic

---



* <center class="half">
  <img src="https://s2.loli.net/2022/04/09/COnvomETrl6GRf2.png" width = "50%" alt="***" align=left />
  <img src="https://s2.loli.net/2022/04/09/7ASmXcCazOh9GsU.png" width = "50%"  alt="***" align=right />
  <center>











* :hammer_and_wrench:**[Sentence Discrimination] Learning Semantic Sentence Embeddings using Sequential Pair-wise Discriminator**,in COLING 2018. [[pdf](https://aclanthology.org/C18-1230/)] [[torch](https://github.com/badripatro/PQG)]





## :framed_picture: Image Caption

* :hammer_and_wrench:**[Image Caption] Generating Diverse and Descriptive Image Captions Using Visual Paraphrases**, in ICCV 2019. [[pdf](https://ieeexplore.ieee.org/document/9010984)] [[torch](https://github.com/pkuliu/visual-paraphrases-captioning)]
  * ËØ•ËÆ∫ÊñáÁ†îÁ©∂‰∫ÜÁõÆÂâçÂõæÂÉèÁöÑÊñáÊú¨ÊèèËø∞ÁöÑ**Â§öÊ†∑ÊÄß**Âíå**ÂÖ∑‰ΩìÊÄß**Áº∫‰πèÁöÑÈóÆÈ¢òÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éËßÜËßâÂ§çËø∞ÁöÑ‰∏§Èò∂ÊÆµËß£Á†ÅÁöÑÊ®°Âûã„ÄÇ
    * ÁªôÂÆöÂõæÂÉèËæìÂÖ•ÔºåËØ•Ê®°ÂûãÈ¶ñÂÖàÁîüÊàêÂàùÊ≠•ÁöÑÂè•Â≠êÔºåÂÜçÂ∞ÜÂÖ∂ÊîπÂÜô‰∏∫ÂÜÖÂÆπÊõ¥Âä†Â§öÊ†∑Âíå‰∏∞ÂØåÁöÑÊèèËø∞„ÄÇÂú®MS COCOÂõæÂÉèÊèèËø∞Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÊòæÁ§∫ÔºåÊñπÊ≥ïÂèØ‰ª•ÊòæËëóÊèêÂçáÊñáÊú¨ÊèèËø∞ÁöÑ**Â§öÊ†∑ÊÄß**Âíå**ÂÖ∑‰ΩìÊÄß**„ÄÇ
  
  * ÈáçÁÇπÊé¢Á¥¢**visual paraphrases** ËßíËâ≤ + **scoring function**
  
    * ```mermaid
      graph LR
      ‰∏é‰∫∫Á±ªÁõ∏ÊØî --ÊñáÁ´†‰∏≠Êúâexample--> Áº∫Â∞ëÂ§öÊ†∑ÊÄßÂíåÂÖ∑‰ΩìÊÄß --> ‰∏§Èò∂ÊÆµËßÜËßâÂ§çËø∞ÊñπÊ≥ï --> MSCOCOÊï∞ÊçÆÈõÜ
      ```
  
  * ÊïÖ‰∫ãÂ±ïÂºÄ:
  
    * ```mermaid
      graph LR
      Ê†áÂáÜ -->ÊµÅÁïÖ+Áõ∏ÂÖ≥+Â§öÊ†∑+ÂÖ∑‰Ωì --Â§öÊ†∑ÊÄß--> ÂΩ¢ÂÆπËØç
      ÊµÅÁïÖ+Áõ∏ÂÖ≥+Â§öÊ†∑+ÂÖ∑‰Ωì --Â§öÊ†∑ÊÄß--> ÁªÜËäÇ,with
      ÂΩ¢ÂÆπËØç --> Pa((Paraphrase))
      ÁªÜËäÇ,with --> Pa
      Pa --> visual-paraphrase
      visual-paraphrase --> sentence_pairs --> ‰∏§Èò∂ÊÆµÁºñÁ†Å
      ```
  
    * ```mermaid
      graph LR
      Áõ∏ÂÖ≥Â∑•‰Ωú --caption--> Â§öcaption.vs.Âçïcaption --paraphrases--> Êú™Â§ÑÁêÜÁâπÂæÅÂíåËßÜËßâ‰ø°ÊÅØ --‰∏§Èò∂ÊÆµÁºñÁ†Å--> ‰∏≠Èó¥seq.vs.2captions 
      ```
  
  * Ê®°ÂûãÊñπÊ≥ïÔºö
  
    * ```mermaid
      graph LR
      ÈÄâÊã©ËßÜËßâÂ§çËø∞captionÂØπ --> ËØÑÂàÜÂáΩÊï∞ --> ËÆæËÆ°‰∏â‰∏™AttentionÊìç‰Ωú,Â≠¶‰π†Âà∞Â§öÊ®°ÊÄÅÁü•ËØÜ --> ÊúÄÂêésoftmaxËæìÂá∫
      ```
  
  * Êõ¥Â§öÁªÜËäÇÂèØËßÅ[slide](https://kdocs.cn/l/conDzdschwAn)


* :fire: :hammer_and_wrench:**[Text Generation & Image Caption] Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions**, in CVPR 2019. [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/html/Cornia_Show_Control_and_Tell_A_Framework_for_Generating_Controllable_and_CVPR_2019_paper.html)] [[torch](https://github.com/aimagelab/show-control-and-tell)]

